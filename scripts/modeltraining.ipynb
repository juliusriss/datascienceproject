{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the implementation of Hector Andres Mejia Vallejo:\n",
    "https://medium.com/analytics-vidhya/distil-roberta-for-hate-speech-classification-and-a-conceptual-review-about-transformers-c283bd8ff827\n",
    "Model was run with Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import html\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "def create_dataset(df):\n",
    "    # Create the labels\n",
    "    df['lyric'] = df['lyrics'].astype(str)\n",
    "    df['label'] = df['explicit'].astype(int)\n",
    "\n",
    "    # Keep only lyric and label column\n",
    "    df = df[['lyric', 'label']]\n",
    "\n",
    "    # Create dataset\n",
    "    lyrics_list = df['lyric'].astype(str).tolist()\n",
    "    labels_list = df['label'].astype(int).tolist()\n",
    "    result = {\"lyric\": lyrics_list, \"label\": labels_list}\n",
    "    ds = Dataset.from_dict(result)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text_encoding function\n",
    "def Text_encoding(ds, tokenizer_name=\"distilroberta-base\"):\n",
    "\n",
    "    #Data splitting\n",
    "    train_ds, test_ds = ds.train_test_split(test_size=0.2).values()\n",
    "\n",
    "    #Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    #Tokenizer function\n",
    "    tokenize_func = lambda sentences: tokenizer(sentences['lyric'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    #Tokenising of Training and Testing data\n",
    "    tok_train_ds = train_ds.map(tokenize_func, batched=True)\n",
    "    tok_test_ds = test_ds.map(tokenize_func, batched=True)\n",
    "\n",
    "    #Save the tokenizer\n",
    "    data_path = Path(__file__).resolve().parents[1] / 'data' / 'final_data' / 'trained_model_explicity'\n",
    "    tokenizer.save_pretrained(data_path)\n",
    "\n",
    "    return tok_train_ds, tok_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction function\n",
    "def model_prediction(tok_train_ds, tok_test_ds, model_name=\"distilroberta-base\", num_labels=2, epochs=5):\n",
    "\n",
    "    # Load the model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # Arguments for training\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    # Calculate metrics\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "\n",
    "        # Confusion matrix\n",
    "        plot_confusion_matrix(labels, preds)\n",
    "\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    def plot_confusion_matrix(y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tok_train_ds,\n",
    "        eval_dataset=tok_test_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Save the model\n",
    "    data_path = Path(__file__).resolve().parents[1] / 'data' / 'final_data' / 'trained_model_explicity'\n",
    "    model.save_pretrained(data_path)\n",
    "\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run all functions defined above\n",
    "def main():\n",
    "\n",
    "    #Load datafile\n",
    "    data_path = Path(__file__).resolve().parents[1] / 'data' / 'final_data' / 'global_17-24_with_polarity_and_spotify.csv'\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    #Create preprocessed dataset\n",
    "    ds = create_dataset(df)\n",
    "    print(ds)\n",
    "\n",
    "    #Text encoding\n",
    "    tok_train_ds, tok_test_ds = Text_encoding(ds)\n",
    "\n",
    "    #Train the model\n",
    "    eval_results = model_prediction(tok_train_ds, tok_test_ds)\n",
    "\n",
    "    #Print the results\n",
    "    print(eval_results)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
